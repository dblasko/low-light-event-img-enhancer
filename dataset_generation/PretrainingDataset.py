from torch.utils.data import dataset
import torchvision.transforms as T
from PIL import Image
import os


class PretrainingDataset(dataset.Dataset):
    """
    Handles the pretraining dataset generated by running `pretraining_generation.py`.
    """

    def __init__(
        self, img_folder, target_img_folder, img_size=64, limit=None, train=True
    ):
        super().__init__()
        self.train = train
        self.filenames = [
            os.path.join(img_folder, file)
            for file in os.listdir(img_folder)
            if not file.startswith(".DS_Store")
        ]
        if limit is not None:
            self.filenames = self.filenames[:limit]
        self.target_filenames = [
            os.path.join(target_img_folder, file)
            for file in os.listdir(target_img_folder)
            if not file.startswith(".DS_Store")
        ]
        if limit is not None:
            self.target_filenames = self.target_filenames[:limit]

        self.transform = (
            T.Compose(
                [
                    T.Resize(img_size),
                    T.RandomCrop((img_size // 2, img_size // 2)),
                    T.ToTensor(),
                    T.Normalize([0.0, 0.0, 0.0], [1.0, 1.0, 1.0]),
                ]
            )
            if train
            else T.Compose(
                [
                    T.Resize(img_size),
                    T.ToTensor(),
                    T.Normalize([0.0, 0.0, 0.0], [1.0, 1.0, 1.0]),
                ]
            )
        )

    def __getitem__(self, idx):
        image = Image.open(self.filenames[idx]).convert("RGB")
        target = Image.open(self.target_filenames[idx]).convert("RGB")

        if (
            not self.train and image.size[0] > image.size[1]
        ):  # to ensure all images of a batch are in the same orientation
            image = image.rotate(90, expand=True)
            target = target.rotate(90, expand=True)

        image = self.transform(image)
        target = self.transform(target)

        if not self.train:  # reshape to dimensions dividible by 8
            if target.shape[1] % 8 != 0:
                target = target[:, : -(target.shape[1] % 8), :]
                image = image[:, : -(image.shape[1] % 8), :]
            if target.shape[2] % 8 != 0:
                target = target[:, :, : -(target.shape[2] % 8)]
                image = image[:, :, : -(image.shape[2] % 8)]

        return image, target

    def __len__(self):
        return len(self.filenames)
